| **Technology**           | **What It Is**                                                                 | **Why It’s Used in RAG**                                                                 | **Deconstruction**                                                                                     | **ELI5 Explanation**                                                                                     | **Competing Products/Alternatives**          |
|--------------------------|-------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|---------------------------------------------|
| **Contextual Rewriting (FLARE)** | A query transformation technique that rewrites user queries to improve clarity and relevance. | Enhances the query to better match relevant documents by adding context or rephrasing. | Breaks down the user’s question, adds more details or rephrases it to make it easier to find answers. | It’s like asking a better question to your friend so they understand exactly what you want to know!      | Query2Doc, ITER-RETGEN (query rewriting tools). |
| **Vector Databases**      | Databases that store data as numerical vectors (embeddings) for fast similarity searches. | Stores document embeddings to quickly retrieve relevant info based on semantic similarity. | Converts text into numbers, stores them, and finds the closest matches to a query’s numbers.       | It’s like a big library where books are turned into magic numbers to find the best ones super fast!   | Pinecone, FAISS, Weaviate, Milvus, Qdrant.   |
| **Metadata Filtering**    | A method to filter data in vector databases using metadata (e.g., tags, dates). | Narrows down search results to more relevant documents based on extra info like source or date. | Uses extra labels on data to pick only the most useful pieces for the query.                     | It’s like picking only the red candies from a big bowl because you know those are your favorites!     | Graph Databases (e.g., Neo4j, Amazon Neptune). |
| **Graph Databases**       | Databases that store data as nodes and edges to represent relationships.     | Retrieves related info by leveraging connections between data points (e.g., citations). | Looks at how things are connected, like friends in a group, to find useful info.                 | It’s like finding friends of your friends to learn more about something you’re curious about!       | Neo4j, Amazon Neptune, Weaviate (hybrid).    |
| **Semantic Chunks**       | Dividing text into meaningful pieces based on semantic content (e.g., sentences, propositions). | Ensures retrieved text chunks are meaningful and contextually relevant.               | Splits text into small, smart pieces that make sense on their own for better understanding.       | It’s like cutting a big story into small parts that still make sense, like chapters in a book!      | Recursive Splits, Sliding Window Methods.    |
| **Propositions**          | Breaking text into individual factual statements or ideas.                   | Improves retrieval by focusing on specific, factual units of information.            | Turns big text into small, true facts to make finding the right info easier.                     | It’s like turning a long story into short facts, so you can find the exact thing you need!          | Sentence Window Retrieval, Auto-merging.     |
| **Dynamic Chunks**        | Adjusting chunk sizes dynamically based on content or query needs.           | Balances context and noise by creating chunks of optimal size for each query.         | Changes how big or small the text pieces are depending on what’s needed for the question.         | It’s like cutting a pizza into bigger or smaller slices depending on how hungry you are!            | Fixed-size Chunking (e.g., 256 tokens).      |
| **Contextual Chunks**     | Chunks that include surrounding context to preserve meaning.                 | Ensures retrieved chunks have enough context to be useful for generation.            | Keeps extra info around each piece of text so it’s not confusing when used.                     | It’s like keeping the page before and after a story part so you understand the whole thing!         | Standard Chunking, Sentence Window Retrieval. |
| **Multi-Hop Retrieval**   | A retrieval method that follows multiple steps or links to find relevant info. | Handles complex queries by retrieving info in stages (e.g., finding related concepts). | Jumps from one piece of info to another, like following clues, to find the best answer.           | It’s like playing a treasure hunt where you find one clue, then another, to get to the treasure!     | Standard Retrieval, Graph-RAG.               |
| **HYDE**                  | Hypothetical Document Embeddings: Creates a fake answer to retrieve similar real documents. | Improves retrieval by matching documents to a hypothetical answer rather than the query. | Makes up a pretend answer, then finds real info that matches it to help with the real question.   | It’s like imagining the answer to your question, then finding real stuff that looks like your guess! | Query2Doc, Step-back Prompting.              |
| **DSP**                   | Differentiable Search Processing: A framework for optimizing retrieval.      | Enhances retrieval accuracy by fine-tuning the search process using machine learning. | Uses smart math to make the search better at finding the right info.                             | It’s like teaching a robot to get better at finding your favorite toy by learning what you like!    | Standard Retrieval, Hybrid Search.           |
| **TF-IDF**                | Term Frequency-Inverse Document Frequency: A statistical measure for keyword relevance. | Helps rank documents based on keyword importance for retrieval or re-ranking.         | Counts how often words appear and how rare they are to decide what’s important.                 | It’s like finding the special words in a story that tell you what it’s really about!                | BM-25, Cosine Similarity.                    |
| **BM-25**                 | A ranking algorithm that improves on TF-IDF by considering document length and term saturation. | Ranks retrieved documents based on keyword relevance, often used in hybrid search.    | Scores documents by how well their words match the question, considering size and word use.      | It’s like giving a score to books based on how many important words they have that match your question! | TF-IDF, Cosine Similarity.                   |
| **Rank Fusion (RRF)**     | Reciprocal Rank Fusion: Combines rankings from multiple search methods.      | Merges results from different retrieval methods (e.g., vector and keyword) for better accuracy. | Takes the best picks from different search styles and mixes them into one great list.           | It’s like asking two friends for their favorite toys, then picking the best ones from both lists!   | Weighted Sum Fusion, Learning-to-Rank (LTR). |
| **Cosine Similarity**     | A metric to measure the similarity between two vectors by their angle.       | Used to find the most similar documents to a query by comparing their embeddings.    | Measures how close two sets of numbers are by looking at their direction, not size.              | It’s like seeing how much two drawings look alike by comparing their shapes, not their colors!      | Euclidean Distance, Dot Product.             |